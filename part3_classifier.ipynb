{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import io\n",
    "\n",
    "rap1_positives = io.read_text_file('./data/rap1-lieb-positives.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACATCCGTGCACCTCCG', 'ACACCCAGACATCGGGC', 'CCACCCGTACCCATGAC', 'GCACCCATACATTACAT', 'ACATCCATACACCCTCT', 'ACACCCTTACACTTTTA', 'GCATCCGTGCCTCCCAC', 'AAACCCATGCACAGTGA', 'ACATCCGTGCACCATTT', 'ACACCCATACATACGGA', 'ACACCCACACCCCGGGC', 'ACCTCCGTACACCAATC', 'ACACCCATACATGTTGA', 'TGACCCATACATTTCCT', 'ACATCCGTACATCAGAA', 'AAACCCATACATATCTT', 'TCACCCAGTCATCCAAC', 'AGACCCACACACCGCAT', 'TAGCCCATACACCGCAG', 'ACACCCACACCCCTCAT', 'ACACCCACGCCCCGCAA', 'GAACCCACACCTCTCAC', 'GCACCCACACATCGCAT', 'AAATCCGTGCACCGCAT', 'AAACCCATGCACCTCCA', 'ACACCCATTCACCGCAC', 'ACATCCGTGCACTGTGG', 'ACATCCATACATTCGGT', 'ACACCCATACATTTATA', 'ACACCCAGACACCTCAA', 'GCACCCGTACCCCACAA', 'ACATCCGAACACCAAAT', 'ACACCCATACCTCTCAG', 'GCACCCGCACACCGCAG', 'ACACCCACACATTTACA', 'AAACCCATACAATATAT', 'ACATCCGTACACTTTTG', 'CCGCCCATACACCCCAT', 'GCACCCACACACCGGAC', 'ACACCCAAACATTAGGG', 'CCATCCATACATTTTGG', 'GCACCCATGCACCTCAC', 'GAACCCATTCACCACAT', 'CCATCCATACATGTTCA', 'ACACCCACACATATCTA', 'AAATCCGTACCTTTCCT', 'GAACCCACACACCACAC', 'AGACCCATACACCCGCT', 'GCATCCATACACCCACC', 'GCACCCGTGCATCATAC', 'CCGCCCATACACCGCAC', 'TCACCCAGACACCTACG', 'TAACCCGTACATGCCCA', 'AAACCCAAACATATTAA', 'GCACCCAAACACCTGCA', 'AGATCCGTACATATCTC', 'ACACCCAAACATATCTA', 'ACACCCATACACACCAA', 'AGACCCATACATCATGA', 'TGACCCATACCCACCGA', 'GAACCCATACATTATTT', 'GCACCCACACATTCTAA', 'GCACCCAGACCATACGT', 'GCACCCACACATTACCG', 'GCACCCACACCTCGCAT', 'ACACCCATACCCCATAA', 'ACATCCATACATCTCCA', 'ACACCCGTACACTTTAT', 'AAATCCAGACACTTCCT', 'GCGCCCATACATCACAT', 'ACATCCACACCTCACTA', 'ACATCCTTGCACCACAC', 'CCACCCATGCACCGCAC', 'CCATCCATACATCCTTT', 'TAACCCATACATATCAT', 'ACATCCTCACACCACTA', 'GCACCCATGCATCCACT', 'ACACCCACACACGACTC', 'AACTCCGTGCACCACAC', 'GCACCCATACCCAGAGT', 'ACATCCGTACATTTAGT', 'ACACCCGCACACCACAA', 'AGATCCGTACATCTTAG', 'ACACCCAAACATTCATT', 'ACATCCATACATTTATG', 'ACCTCCGTGCATCCTGT', 'ACACCCACGCATCTCAT', 'GCATCCGTGCCTCCTGG', 'ACATCCGAACATTTCAC', 'GGACCCATGCACCACAT', 'GCACCCAGTCACCGCCC', 'GAACCCATGCACCACAC', 'AAACCCAGACATCCCAT', 'ACATCCGTGCATTACAT', 'ACATCCATACATTTTTT', 'AAATCCGTACACACTAC', 'GCGTCCGTACACTGTCC', 'GCACCCATACATTATAA', 'GCACCCATACATTTATA', 'ACACCCGTACATTTCAC', 'GAACCCAAACATTATAG', 'ACATCCATACCTTTCCT', 'GAACCCATTCATCCAAT', 'TAATCCGTACACCGCGC', 'ACGCCCAGACATAACAT', 'GCACCCGCGCCTTCCTC', 'CCACCCGAACACCTCAC', 'ACACCCATGCATTATTG', 'ACACCCGTACATATTAA', 'CCACCCGTACACCTCCC', 'AAACCCGGACATTCCAT', 'AAACCCATACACAATGA', 'ACACCCAAACATATGAT', 'ACACCCAGTCATCCGGC', 'GAACCCATACCCCATTT', 'ACACCCATACAAACCCA', 'ACACCCATTCATCACGT', 'ACATCCGTACCTTTCCA', 'CCATCCATACCTTAGCA', 'ACACCCATGCATCATTC', 'GAACCCATACATTTCAA', 'ACATCCGTACATTCGAG', 'GAATCCACACACCGCAT', 'ACACCCTTACACTTCCT', 'AAACCCATACACCATTT', 'AAACCCATGCATCGGTT', 'AAATCCGTACATTTCTG', 'AAACCCAAACACCACAT', 'TCACCCGTACATCCACG', 'CCACCCACGCATCCAAA', 'GAATCCGTACATTTAGA', 'ACACCCAAGCACAGCAT', 'GAATCCTTACATCACAC', 'ACACCCATACCTTTAGG', 'AGACCCATACATCACAA', 'TAACCCATACACCTCAT', 'ACACCCATACACCAAAC']\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "print(rap1_positives)\n",
    "print(len(rap1_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n"
     ]
    }
   ],
   "source": [
    "# variance bewteen seq lengths:\n",
    "\n",
    "print(set([len(seq) for seq in rap1_positives]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap1_negatives = io.read_fasta_file('./data/yeast-upstream-1k-negative.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCAATTTGTCACCAGCTTCAGAAATGGTGTTCTTCAAAGAGTAAGCAATGGATTCCAATTGGTTCTTGGAAGCAATTCTTTGAGATTCCTTTTCATCTTCTTCCTTGAATTTTTCGGCTTCAGCAACCATCTTTTCGATATCTTCCTTGGACAATCTACCCTTGTCGTTGGTAATAGTGATCTTGTTAGACTTACCAGTACCCTTTTCGACGGCGGAAACATTCAAAATACCGTTAGAGTCGACATCGAAAGTGACTTCAATTTGTGGGACACCTCTTGGAGCTGGTGGAATACCACTCAATTCGAACTTACCCAACAAGTTGTTGTCCTTAGTCTTGGCTCTTTCACCTTCAAAGACTTGAATCAAGACACCTGGTTGGTTATCAGCATAAGTGGAAAAGATCTCGAACTTCTTTGTTGAAATGGTAGAGTTTCTTGGAATCAACTTGGTCATGACACCACCAGCAGTTTCAATACCCAAGGATAATGGAGCGACATCCAACAACAATAGATCTTGAGTCTTGGAAGATTCGTCACCAGTCAAAATAGCAGCTTGAACAGCAGCACCGTAAGCAACAGCTTCATCTGGGTTGATAGATCTGTTTGGTTCCTTACCGTTGAAGTAGTCAGTGACCAATTTTTGGACCTTTGGAATTCTGGTAGAACCACCGACCAAGACAATTTCATCGACTTGAGATTTGTCCAATTTAGCATCTCTCAAGACCTTTTCAACTGGGTCCAAAGTAGATCTGAACAAGTCAGCACACAATTCTTCGAATCTGGCTCTGGTGATGGAAGTGTAGAAATCGATACCTTCGAACAAAGAGTCAATTTCAACGGAAGTTTGAGCGGAGGAAGACAAAGTTCTCTTGGCTCTTTCACAAGCGGTTCTTAATCTTCTCAAAGCTCTTTGGTTGGTAGACAAGTCCTTCTTGTTCTTTCTCTTGAATTCTTGGATGAAGTGGTTGACCAATCTGTTGTCAAAATCTTCACCACCCAA\n",
      "3163\n"
     ]
    }
   ],
   "source": [
    "print(rap1_negatives[1])\n",
    "print(len(rap1_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1000, 490, 334, 52, 629, 792}\n"
     ]
    }
   ],
   "source": [
    "print(set([len(seq) for seq in rap1_negatives]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split negative sequences into size 17 (matching negative)\n",
    "\n",
    "rap1_negatives_split = []\n",
    "for seq in rap1_negatives:\n",
    "    for i in range(0, len(seq), 17):\n",
    "        rap1_negatives_split.append(seq[i:i+17])\n",
    "\n",
    "rap1_negatives_split = [s for s in rap1_negatives_split if len(s) == 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17}\n"
     ]
    }
   ],
   "source": [
    "print(set([len(seq) for seq in rap1_negatives_split]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183297"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rap1_negatives_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample data\n",
    "\n",
    "from nn import preprocess\n",
    "\n",
    "X , y = preprocess.sample_seqs( rap1_positives + rap1_negatives_split ,\n",
    "                                [1]*len(rap1_positives) + [0]*len(rap1_negatives_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one hot\n",
    "\n",
    "for idx, seq in enumerate(X):\n",
    "    X[idx] = preprocess.one_hot_encode_seqs(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{68}\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "print(set([len(seq_one_hot) for seq_one_hot in X]))\n",
    "\n",
    "print( 17 * 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# cast to np arrays, transpose to match nn (feature, batch) code\n",
    "X_train, X_val, y_train, y_val = np.array(X_train).T, np.array(X_val).T, np.array(y_train), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 293275)\n",
      "(68, 73319)\n",
      "(293275,)\n",
      "(73319,)\n"
     ]
    }
   ],
   "source": [
    "for i in (X_train, X_val, y_train, y_val):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  \tTraining Loss: 0.7208151436654644\tValidation Loss: 0.7047028373108098\n",
      "Epoch 2  \tTraining Loss: 0.704338226875035\tValidation Loss: 0.6900106359841279\n",
      "Epoch 3  \tTraining Loss: 0.6896564116288653\tValidation Loss: 0.6766193829452353\n",
      "Epoch 4  \tTraining Loss: 0.6762747937880869\tValidation Loss: 0.6641916756722188\n",
      "Epoch 5  \tTraining Loss: 0.6638548541243003\tValidation Loss: 0.6523699203586402\n",
      "Epoch 6  \tTraining Loss: 0.6520403566825739\tValidation Loss: 0.6409086517939695\n",
      "Epoch 7  \tTraining Loss: 0.6405846837687382\tValidation Loss: 0.6296659524141586\n",
      "Epoch 8  \tTraining Loss: 0.6293466615410892\tValidation Loss: 0.6185489229225016\n",
      "Epoch 9  \tTraining Loss: 0.6182345345497928\tValidation Loss: 0.6074978743949059\n",
      "Epoch 10  \tTraining Loss: 0.6071885409229761\tValidation Loss: 0.5963520414417649\n",
      "Epoch 11  \tTraining Loss: 0.5960468575384814\tValidation Loss: 0.5850490409154075\n",
      "Epoch 12  \tTraining Loss: 0.5847472838771488\tValidation Loss: 0.5735951488873449\n",
      "Epoch 13  \tTraining Loss: 0.5732980928905547\tValidation Loss: 0.5619753087270853\n",
      "Epoch 14  \tTraining Loss: 0.5616837725722785\tValidation Loss: 0.5501399723179722\n",
      "Epoch 15  \tTraining Loss: 0.5498554265245019\tValidation Loss: 0.5380677675777935\n",
      "Epoch 16  \tTraining Loss: 0.5377893465425645\tValidation Loss: 0.525756580286553\n",
      "Epoch 17  \tTraining Loss: 0.525483978266503\tValidation Loss: 0.5131938524261022\n",
      "Epoch 18  \tTraining Loss: 0.5129285162075558\tValidation Loss: 0.5004190735581915\n",
      "Epoch 19  \tTraining Loss: 0.5001625674274892\tValidation Loss: 0.4874239508599366\n",
      "Epoch 20  \tTraining Loss: 0.4871769267210393\tValidation Loss: 0.4742353332403805\n",
      "Epoch 21  \tTraining Loss: 0.4739980929720671\tValidation Loss: 0.460870312619397\n",
      "Epoch 22  \tTraining Loss: 0.46064430084400754\tValidation Loss: 0.4473566530098099\n",
      "Epoch 23  \tTraining Loss: 0.4471424145591752\tValidation Loss: 0.43371162054663176\n",
      "Epoch 24  \tTraining Loss: 0.4335086309753612\tValidation Loss: 0.41998618066617216\n",
      "Epoch 25  \tTraining Loss: 0.4197943978493361\tValidation Loss: 0.4062221621544774\n",
      "Epoch 26  \tTraining Loss: 0.4060404927959732\tValidation Loss: 0.39247857756220034\n",
      "Epoch 27  \tTraining Loss: 0.3923064783341174\tValidation Loss: 0.3787840851885685\n",
      "Epoch 28  \tTraining Loss: 0.37862193828954105\tValidation Loss: 0.365190313453557\n",
      "Epoch 29  \tTraining Loss: 0.36503978501547846\tValidation Loss: 0.351726312239451\n",
      "Epoch 30  \tTraining Loss: 0.3515894077101688\tValidation Loss: 0.3384595913483508\n",
      "Epoch 31  \tTraining Loss: 0.3383368951582219\tValidation Loss: 0.3254338793447556\n",
      "Epoch 32  \tTraining Loss: 0.3253246719496476\tValidation Loss: 0.31266818612674235\n",
      "Epoch 33  \tTraining Loss: 0.3125720257207306\tValidation Loss: 0.30019288217840195\n",
      "Epoch 34  \tTraining Loss: 0.30010848419253416\tValidation Loss: 0.2880690975984858\n",
      "Epoch 35  \tTraining Loss: 0.2879955948718011\tValidation Loss: 0.27630274305420455\n",
      "Epoch 36  \tTraining Loss: 0.2762388520001392\tValidation Loss: 0.26492116463085436\n",
      "Epoch 37  \tTraining Loss: 0.26486690990168515\tValidation Loss: 0.25393854606075517\n",
      "Epoch 38  \tTraining Loss: 0.2538926941192072\tValidation Loss: 0.2433751371317339\n",
      "Epoch 39  \tTraining Loss: 0.24333708927450562\tValidation Loss: 0.2332373868008817\n",
      "Epoch 40  \tTraining Loss: 0.2332064350480753\tValidation Loss: 0.22352406436735994\n",
      "Epoch 41  \tTraining Loss: 0.2235003120532977\tValidation Loss: 0.21423620989006717\n",
      "Epoch 42  \tTraining Loss: 0.21421887594515987\tValidation Loss: 0.20537645266276228\n",
      "Epoch 43  \tTraining Loss: 0.2053655563750339\tValidation Loss: 0.1969331870311165\n",
      "Epoch 44  \tTraining Loss: 0.19692845565110126\tValidation Loss: 0.18889694987921876\n",
      "Epoch 45  \tTraining Loss: 0.18889806447571733\tValidation Loss: 0.1812539892249985\n",
      "Epoch 46  \tTraining Loss: 0.18126046572090884\tValidation Loss: 0.17398918089027923\n",
      "Epoch 47  \tTraining Loss: 0.17400031807489222\tValidation Loss: 0.1670895016910544\n",
      "Epoch 48  \tTraining Loss: 0.16710448404208758\tValidation Loss: 0.16054038630486384\n",
      "Epoch 49  \tTraining Loss: 0.16055874652981386\tValidation Loss: 0.1543245585990278\n",
      "Epoch 50  \tTraining Loss: 0.15434568785734798\tValidation Loss: 0.14843326875007853\n",
      "Epoch 51  \tTraining Loss: 0.14845628101150932\tValidation Loss: 0.14285000635173714\n",
      "Epoch 52  \tTraining Loss: 0.14287437065983447\tValidation Loss: 0.1375567061681276\n",
      "Epoch 53  \tTraining Loss: 0.13758190864678432\tValidation Loss: 0.13253785582272667\n",
      "Epoch 54  \tTraining Loss: 0.13256339544128998\tValidation Loss: 0.12778263594343378\n",
      "Epoch 55  \tTraining Loss: 0.1278078848819384\tValidation Loss: 0.12327539492871116\n",
      "Epoch 56  \tTraining Loss: 0.1233000310764547\tValidation Loss: 0.11900094429628626\n",
      "Epoch 57  \tTraining Loss: 0.11902484394283207\tValidation Loss: 0.11494436707928155\n",
      "Epoch 58  \tTraining Loss: 0.11496745671894334\tValidation Loss: 0.11109549601851197\n",
      "Epoch 59  \tTraining Loss: 0.11111751705700111\tValidation Loss: 0.10744185518161498\n",
      "Epoch 60  \tTraining Loss: 0.10746249336902608\tValidation Loss: 0.1039714831349528\n",
      "Epoch 61  \tTraining Loss: 0.10399043218204403\tValidation Loss: 0.10067518009943036\n",
      "Epoch 62  \tTraining Loss: 0.10069243926165677\tValidation Loss: 0.09754136010430582\n",
      "Epoch 63  \tTraining Loss: 0.09755686334603447\tValidation Loss: 0.0945609706850498\n",
      "Epoch 64  \tTraining Loss: 0.09457465750514549\tValidation Loss: 0.09172607308775206\n",
      "Epoch 65  \tTraining Loss: 0.09173777137131925\tValidation Loss: 0.08902760350368956\n",
      "Epoch 66  \tTraining Loss: 0.0890373758537199\tValidation Loss: 0.08645704648496423\n",
      "Epoch 67  \tTraining Loss: 0.08646496285445446\tValidation Loss: 0.08400663095199436\n",
      "Epoch 68  \tTraining Loss: 0.08401263326441495\tValidation Loss: 0.08166975642019038\n",
      "Epoch 69  \tTraining Loss: 0.08167385496201802\tValidation Loss: 0.0794403364495596\n",
      "Epoch 70  \tTraining Loss: 0.07944248552717326\tValidation Loss: 0.07731272976909832\n",
      "Epoch 71  \tTraining Loss: 0.07731295462689938\tValidation Loss: 0.07528056112327981\n",
      "Epoch 72  \tTraining Loss: 0.07527889631086906\tValidation Loss: 0.07333800290698962\n",
      "Epoch 73  \tTraining Loss: 0.07333450597010463\tValidation Loss: 0.07148002228831167\n",
      "Epoch 74  \tTraining Loss: 0.07147473508509711\tValidation Loss: 0.06970206237930329\n",
      "Epoch 75  \tTraining Loss: 0.06969511130718449\tValidation Loss: 0.06799942473747642\n",
      "Epoch 76  \tTraining Loss: 0.06799093141453705\tValidation Loss: 0.06636748526662484\n",
      "Epoch 77  \tTraining Loss: 0.06635738865144968\tValidation Loss: 0.06480304270228233\n",
      "Epoch 78  \tTraining Loss: 0.06479141568918864\tValidation Loss: 0.06330303178505413\n",
      "Epoch 79  \tTraining Loss: 0.06328998235550963\tValidation Loss: 0.061863848425623716\n",
      "Epoch 80  \tTraining Loss: 0.061849371859859135\tValidation Loss: 0.06048233756871675\n",
      "Epoch 81  \tTraining Loss: 0.06046646872238193\tValidation Loss: 0.059155366976785445\n",
      "Epoch 82  \tTraining Loss: 0.05913816590773139\tValidation Loss: 0.05787969758041505\n",
      "Epoch 83  \tTraining Loss: 0.05786120770039167\tValidation Loss: 0.05665282806855399\n",
      "Epoch 84  \tTraining Loss: 0.05663305158760419\tValidation Loss: 0.05547225369690316\n",
      "Epoch 85  \tTraining Loss: 0.05545113691183272\tValidation Loss: 0.0543358867533383\n",
      "Epoch 86  \tTraining Loss: 0.05431342634447632\tValidation Loss: 0.05324113083969057\n",
      "Epoch 87  \tTraining Loss: 0.053217377090283936\tValidation Loss: 0.052185914860238256\n",
      "Epoch 88  \tTraining Loss: 0.052160868025558214\tValidation Loss: 0.05116902101191229\n",
      "Epoch 89  \tTraining Loss: 0.05114270942330622\tValidation Loss: 0.05018807070838412\n",
      "Epoch 90  \tTraining Loss: 0.050160505496120486\tValidation Loss: 0.04924142393050942\n",
      "Epoch 91  \tTraining Loss: 0.04921267874017406\tValidation Loss: 0.048327396468541645\n",
      "Epoch 92  \tTraining Loss: 0.04829749393540992\tValidation Loss: 0.04744462525590858\n",
      "Epoch 93  \tTraining Loss: 0.04741361876040554\tValidation Loss: 0.046591352928393955\n",
      "Epoch 94  \tTraining Loss: 0.04655935816307726\tValidation Loss: 0.04576651761959482\n",
      "Epoch 95  \tTraining Loss: 0.04573364330863893\tValidation Loss: 0.04496877621436542\n",
      "Epoch 96  \tTraining Loss: 0.044935040104572735\tValidation Loss: 0.04419713896448079\n",
      "Epoch 97  \tTraining Loss: 0.044162548687134116\tValidation Loss: 0.04345042165702265\n",
      "Epoch 98  \tTraining Loss: 0.043415008123605894\tValidation Loss: 0.042727485648245106\n",
      "Epoch 99  \tTraining Loss: 0.04269129718053669\tValidation Loss: 0.04202707630367814\n",
      "Epoch 100  \tTraining Loss: 0.04199011954228447\tValidation Loss: 0.041348091879555834\n",
      "Epoch 101  \tTraining Loss: 0.041310442690883235\tValidation Loss: 0.04068965089953768\n",
      "Epoch 102  \tTraining Loss: 0.04065134209522299\tValidation Loss: 0.040051085514031894\n",
      "Epoch 103  \tTraining Loss: 0.040012082316320634\tValidation Loss: 0.0394314768142911\n",
      "Epoch 104  \tTraining Loss: 0.03939179474437906\tValidation Loss: 0.03883011919017092\n",
      "Epoch 105  \tTraining Loss: 0.03878976610868018\tValidation Loss: 0.038246238810906656\n",
      "Epoch 106  \tTraining Loss: 0.038205220463178674\tValidation Loss: 0.037679021642565556\n",
      "Epoch 107  \tTraining Loss: 0.03763735827858085\tValidation Loss: 0.03712780496521314\n",
      "Epoch 108  \tTraining Loss: 0.037085525602452867\tValidation Loss: 0.03659217815638853\n",
      "Epoch 109  \tTraining Loss: 0.03654931767603503\tValidation Loss: 0.036071803835128875\n",
      "Epoch 110  \tTraining Loss: 0.03602840528315026\tValidation Loss: 0.035566249103125405\n",
      "Epoch 111  \tTraining Loss: 0.03552230668962187\tValidation Loss: 0.035074296058140386\n",
      "Epoch 112  \tTraining Loss: 0.0350298530512827\tValidation Loss: 0.03459560261868113\n",
      "Epoch 113  \tTraining Loss: 0.03455069360100113\tValidation Loss: 0.03412993100966101\n",
      "Epoch 114  \tTraining Loss: 0.034084573959129186\tValidation Loss: 0.033676664332315434\n",
      "Epoch 115  \tTraining Loss: 0.033630871981733014\tValidation Loss: 0.03323508524331298\n",
      "Epoch 116  \tTraining Loss: 0.033188872467786054\tValidation Loss: 0.03280478302183223\n",
      "Epoch 117  \tTraining Loss: 0.03275820213438702\tValidation Loss: 0.03238540797419323\n",
      "Epoch 118  \tTraining Loss: 0.032338454241849585\tValidation Loss: 0.0319765767291989\n",
      "Epoch 119  \tTraining Loss: 0.0319292356663041\tValidation Loss: 0.03157790867202139\n",
      "Epoch 120  \tTraining Loss: 0.03153016332211902\tValidation Loss: 0.03118904194018406\n",
      "Epoch 121  \tTraining Loss: 0.031140907356890565\tValidation Loss: 0.03080954834629837\n",
      "Epoch 122  \tTraining Loss: 0.030761041942352598\tValidation Loss: 0.030439103779929737\n",
      "Epoch 123  \tTraining Loss: 0.03039024191559438\tValidation Loss: 0.030077502595034052\n",
      "Epoch 124  \tTraining Loss: 0.03002831946287829\tValidation Loss: 0.029724431243934892\n",
      "Epoch 125  \tTraining Loss: 0.029674946451347023\tValidation Loss: 0.029379769345889404\n",
      "Epoch 126  \tTraining Loss: 0.029329969749068183\tValidation Loss: 0.02904310886513848\n",
      "Epoch 127  \tTraining Loss: 0.028993024710588382\tValidation Loss: 0.028714218530953916\n",
      "Epoch 128  \tTraining Loss: 0.028663877244357018\tValidation Loss: 0.028392786613257087\n",
      "Epoch 129  \tTraining Loss: 0.02834220983367851\tValidation Loss: 0.028078597494791586\n",
      "Epoch 130  \tTraining Loss: 0.02802778762564299\tValidation Loss: 0.027771502313552722\n",
      "Epoch 131  \tTraining Loss: 0.02772048492892661\tValidation Loss: 0.027471157160035783\n",
      "Epoch 132  \tTraining Loss: 0.027419949685524424\tValidation Loss: 0.027177365010931594\n",
      "Epoch 133  \tTraining Loss: 0.02712598363835225\tValidation Loss: 0.026889867777565912\n",
      "Epoch 134  \tTraining Loss: 0.026838333877141594\tValidation Loss: 0.026608462747362047\n",
      "Epoch 135  \tTraining Loss: 0.02655680047009227\tValidation Loss: 0.026332999040821384\n",
      "Epoch 136  \tTraining Loss: 0.026281223572605802\tValidation Loss: 0.026063281995570627\n",
      "Epoch 137  \tTraining Loss: 0.026011397698587114\tValidation Loss: 0.02579914600068094\n",
      "Epoch 138  \tTraining Loss: 0.02574716979409477\tValidation Loss: 0.02554042675668501\n",
      "Epoch 139  \tTraining Loss: 0.025488376500576938\tValidation Loss: 0.02528701085391848\n",
      "Epoch 140  \tTraining Loss: 0.025234876795630485\tValidation Loss: 0.02503872057090682\n",
      "Epoch 141  \tTraining Loss: 0.02498650168779099\tValidation Loss: 0.024795443823964303\n",
      "Epoch 142  \tTraining Loss: 0.024743140503746316\tValidation Loss: 0.024556957481400226\n",
      "Epoch 143  \tTraining Loss: 0.02450457872672497\tValidation Loss: 0.02432320650869314\n",
      "Epoch 144  \tTraining Loss: 0.024270758629862083\tValidation Loss: 0.02409406155393719\n",
      "Epoch 145  \tTraining Loss: 0.02404154929893631\tValidation Loss: 0.023869318531568227\n",
      "Epoch 146  \tTraining Loss: 0.023816751450272147\tValidation Loss: 0.023648849242253887\n",
      "Epoch 147  \tTraining Loss: 0.023596243476018228\tValidation Loss: 0.023432560904287265\n",
      "Epoch 148  \tTraining Loss: 0.02337994652612644\tValidation Loss: 0.02322033244897313\n",
      "Epoch 149  \tTraining Loss: 0.023167712917129282\tValidation Loss: 0.023012054731244676\n",
      "Epoch 150  \tTraining Loss: 0.0229594422449416\tValidation Loss: 0.02280758787332943\n",
      "Epoch 151  \tTraining Loss: 0.022755003330231387\tValidation Loss: 0.022606888988493105\n",
      "Epoch 152  \tTraining Loss: 0.022554347516720672\tValidation Loss: 0.022409940157406924\n",
      "Epoch 153  \tTraining Loss: 0.022357442399978295\tValidation Loss: 0.022216664206615784\n",
      "Epoch 154  \tTraining Loss: 0.0221642341707861\tValidation Loss: 0.02202680754302936\n",
      "Epoch 155  \tTraining Loss: 0.021974458825610253\tValidation Loss: 0.021840330098317772\n",
      "Epoch 156  \tTraining Loss: 0.02178806535094187\tValidation Loss: 0.021657176843841545\n",
      "Epoch 157  \tTraining Loss: 0.021605004997003303\tValidation Loss: 0.02147718497756696\n",
      "Epoch 158  \tTraining Loss: 0.021425128965256727\tValidation Loss: 0.02130026063919145\n",
      "Epoch 159  \tTraining Loss: 0.021248349036869833\tValidation Loss: 0.02112634837854189\n",
      "Epoch 160  \tTraining Loss: 0.021074594889018586\tValidation Loss: 0.02095544369988777\n",
      "Epoch 161  \tTraining Loss: 0.020903842970404686\tValidation Loss: 0.020787444608621267\n",
      "Epoch 162  \tTraining Loss: 0.020735991000755353\tValidation Loss: 0.020622306920673492\n",
      "Epoch 163  \tTraining Loss: 0.020570995173129575\tValidation Loss: 0.020459945933140176\n",
      "Epoch 164  \tTraining Loss: 0.020408775330227415\tValidation Loss: 0.020300283694094094\n",
      "Epoch 165  \tTraining Loss: 0.020249262736876765\tValidation Loss: 0.020143215300475574\n",
      "Epoch 166  \tTraining Loss: 0.020092340750604943\tValidation Loss: 0.01998870975660348\n",
      "Epoch 167  \tTraining Loss: 0.019937990588773945\tValidation Loss: 0.01983673151759626\n",
      "Epoch 168  \tTraining Loss: 0.019786170776537052\tValidation Loss: 0.01968725332356704\n",
      "Epoch 169  \tTraining Loss: 0.019636847739744407\tValidation Loss: 0.019540192521032167\n",
      "Epoch 170  \tTraining Loss: 0.01948994766154634\tValidation Loss: 0.019395438880930767\n",
      "Epoch 171  \tTraining Loss: 0.019345360267465965\tValidation Loss: 0.019252980057921247\n",
      "Epoch 172  \tTraining Loss: 0.019203073439659435\tValidation Loss: 0.019112776427237257\n",
      "Epoch 173  \tTraining Loss: 0.019063039927161983\tValidation Loss: 0.0189747209376141\n",
      "Epoch 174  \tTraining Loss: 0.018925158133822537\tValidation Loss: 0.018838795781993423\n",
      "Epoch 175  \tTraining Loss: 0.018789405993443305\tValidation Loss: 0.018704930755231264\n",
      "Epoch 176  \tTraining Loss: 0.01865571275582902\tValidation Loss: 0.018573070724893292\n",
      "Epoch 177  \tTraining Loss: 0.018524032739731005\tValidation Loss: 0.01844316778980015\n",
      "Epoch 178  \tTraining Loss: 0.01839431335672878\tValidation Loss: 0.01831517268572909\n",
      "Epoch 179  \tTraining Loss: 0.018266516026093207\tValidation Loss: 0.018189042506214736\n",
      "Epoch 180  \tTraining Loss: 0.018140595522080808\tValidation Loss: 0.018064824656389474\n",
      "Epoch 181  \tTraining Loss: 0.018016581439614755\tValidation Loss: 0.01794251810033994\n",
      "Epoch 182  \tTraining Loss: 0.017894474399372518\tValidation Loss: 0.017821959822024835\n",
      "Epoch 183  \tTraining Loss: 0.017774123792342545\tValidation Loss: 0.01770312365972726\n",
      "Epoch 184  \tTraining Loss: 0.017655501095429897\tValidation Loss: 0.017585975058521254\n",
      "Epoch 185  \tTraining Loss: 0.017538567897743655\tValidation Loss: 0.017470492857862657\n",
      "Epoch 186  \tTraining Loss: 0.017423295677628528\tValidation Loss: 0.017356640335995575\n",
      "Epoch 187  \tTraining Loss: 0.017309648653062726\tValidation Loss: 0.01724440359842835\n",
      "Epoch 188  \tTraining Loss: 0.017197624307496127\tValidation Loss: 0.017133742710421094\n",
      "Epoch 189  \tTraining Loss: 0.017087182390033834\tValidation Loss: 0.01702458357504452\n",
      "Epoch 190  \tTraining Loss: 0.016978252265165767\tValidation Loss: 0.016916901909778993\n",
      "Epoch 191  \tTraining Loss: 0.016870803093135604\tValidation Loss: 0.016810664817435032\n",
      "Epoch 192  \tTraining Loss: 0.016764809823812187\tValidation Loss: 0.016705857253193502\n",
      "Epoch 193  \tTraining Loss: 0.016660251555285357\tValidation Loss: 0.016602442128842376\n",
      "Epoch 194  \tTraining Loss: 0.016557089430400775\tValidation Loss: 0.01650039367562517\n",
      "Epoch 195  \tTraining Loss: 0.016455299185838528\tValidation Loss: 0.016399695104483893\n",
      "Epoch 196  \tTraining Loss: 0.016354872596238863\tValidation Loss: 0.016300322282934956\n",
      "Epoch 197  \tTraining Loss: 0.01625577434060277\tValidation Loss: 0.016202239780289066\n",
      "Epoch 198  \tTraining Loss: 0.01615796493513943\tValidation Loss: 0.016105426153375572\n",
      "Epoch 199  \tTraining Loss: 0.016061424500693217\tValidation Loss: 0.016009873123493727\n",
      "Epoch 200  \tTraining Loss: 0.015966145324627548\tValidation Loss: 0.01591554901122599\n",
      "Epoch 201  \tTraining Loss: 0.015872093788580604\tValidation Loss: 0.015822439324703712\n",
      "Epoch 202  \tTraining Loss: 0.015779257563014532\tValidation Loss: 0.01573052903183677\n",
      "Epoch 203  \tTraining Loss: 0.015687623746872773\tValidation Loss: 0.015639811876640992\n",
      "Epoch 204  \tTraining Loss: 0.0155971854584612\tValidation Loss: 0.015550274349842597\n",
      "Epoch 205  \tTraining Loss: 0.015507928563172738\tValidation Loss: 0.015461851817380473\n",
      "Epoch 206  \tTraining Loss: 0.01541980272160748\tValidation Loss: 0.015374537521872839\n",
      "Epoch 207  \tTraining Loss: 0.015332777372551482\tValidation Loss: 0.015288304514392018\n",
      "Epoch 208  \tTraining Loss: 0.01524683299308125\tValidation Loss: 0.015203150677869159\n",
      "Epoch 209  \tTraining Loss: 0.015161965974826375\tValidation Loss: 0.01511902361834961\n",
      "Epoch 210  \tTraining Loss: 0.015078130216691216\tValidation Loss: 0.01503590135535793\n",
      "Epoch 211  \tTraining Loss: 0.01499530642119695\tValidation Loss: 0.014953766909959879\n",
      "Epoch 212  \tTraining Loss: 0.014913477345352531\tValidation Loss: 0.014872606371760093\n",
      "Epoch 213  \tTraining Loss: 0.014832624837466649\tValidation Loss: 0.014792410192455458\n",
      "Epoch 214  \tTraining Loss: 0.01475273701976029\tValidation Loss: 0.01471319330317044\n",
      "Epoch 215  \tTraining Loss: 0.014673825215640979\tValidation Loss: 0.01463490575280051\n",
      "Epoch 216  \tTraining Loss: 0.014595840101524813\tValidation Loss: 0.014557524648780495\n",
      "Epoch 217  \tTraining Loss: 0.01451875691357015\tValidation Loss: 0.01448102639927854\n",
      "Epoch 218  \tTraining Loss: 0.014442558796015107\tValidation Loss: 0.014405408686178215\n",
      "Epoch 219  \tTraining Loss: 0.014367237950108622\tValidation Loss: 0.014330648557027707\n",
      "Epoch 220  \tTraining Loss: 0.014292774734686474\tValidation Loss: 0.014256728907711486\n",
      "Epoch 221  \tTraining Loss: 0.014219156220428134\tValidation Loss: 0.01418363940807255\n",
      "Epoch 222  \tTraining Loss: 0.014146370740111358\tValidation Loss: 0.014111367073919842\n",
      "Epoch 223  \tTraining Loss: 0.014074402864963377\tValidation Loss: 0.014039896247265461\n",
      "Epoch 224  \tTraining Loss: 0.014003233478415414\tValidation Loss: 0.013969209621115615\n",
      "Epoch 225  \tTraining Loss: 0.013932851532003798\tValidation Loss: 0.013899303669704039\n",
      "Epoch 226  \tTraining Loss: 0.013863259750428705\tValidation Loss: 0.013830165746866706\n",
      "Epoch 227  \tTraining Loss: 0.01379443880715849\tValidation Loss: 0.01376177480628052\n",
      "Epoch 228  \tTraining Loss: 0.01372636656494717\tValidation Loss: 0.013694114519596226\n",
      "Epoch 229  \tTraining Loss: 0.013659026380433661\tValidation Loss: 0.013627189467416242\n",
      "Epoch 230  \tTraining Loss: 0.013592426759030088\tValidation Loss: 0.01356098483283095\n",
      "Epoch 231  \tTraining Loss: 0.013526551376814409\tValidation Loss: 0.013495478373438638\n",
      "Epoch 232  \tTraining Loss: 0.013461380509418497\tValidation Loss: 0.013430641484831746\n",
      "Epoch 233  \tTraining Loss: 0.013396886128590536\tValidation Loss: 0.013366499352371707\n",
      "Epoch 234  \tTraining Loss: 0.013333085140056862\tValidation Loss: 0.013303091156900456\n",
      "Epoch 235  \tTraining Loss: 0.0132700144700371\tValidation Loss: 0.013240356677879029\n",
      "Epoch 236  \tTraining Loss: 0.013207615999687101\tValidation Loss: 0.013178284605727604\n",
      "Epoch 237  \tTraining Loss: 0.013145877201219652\tValidation Loss: 0.0131168478390352\n",
      "Epoch 238  \tTraining Loss: 0.013084772947133503\tValidation Loss: 0.013056037567215684\n",
      "Epoch 239  \tTraining Loss: 0.013024297021971573\tValidation Loss: 0.012995847688132958\n",
      "Epoch 240  \tTraining Loss: 0.012964443236654497\tValidation Loss: 0.012936272364778817\n",
      "Epoch 241  \tTraining Loss: 0.012905203146126571\tValidation Loss: 0.012877302807998708\n",
      "Epoch 242  \tTraining Loss: 0.012846567412558522\tValidation Loss: 0.012818932969136271\n",
      "Epoch 243  \tTraining Loss: 0.012788534448290872\tValidation Loss: 0.012761152364082646\n",
      "Epoch 244  \tTraining Loss: 0.012731091067280969\tValidation Loss: 0.012703949199671405\n",
      "Epoch 245  \tTraining Loss: 0.012674227165924012\tValidation Loss: 0.012647309417905006\n",
      "Epoch 246  \tTraining Loss: 0.012617929840253282\tValidation Loss: 0.012591227723905798\n",
      "Epoch 247  \tTraining Loss: 0.012562191669596797\tValidation Loss: 0.01253570783628102\n",
      "Epoch 248  \tTraining Loss: 0.012507013973694475\tValidation Loss: 0.012480733750255935\n",
      "Epoch 249  \tTraining Loss: 0.012452381762448707\tValidation Loss: 0.012426296144465457\n",
      "Epoch 250  \tTraining Loss: 0.012398284754580002\tValidation Loss: 0.012372387072212552\n",
      "Epoch 251  \tTraining Loss: 0.012344712709105083\tValidation Loss: 0.012319006083991252\n",
      "Epoch 252  \tTraining Loss: 0.01229166811946768\tValidation Loss: 0.012266142568578586\n",
      "Epoch 253  \tTraining Loss: 0.012239142525748134\tValidation Loss: 0.012213783959859992\n",
      "Epoch 254  \tTraining Loss: 0.012187120062473727\tValidation Loss: 0.012161926431640154\n",
      "Epoch 255  \tTraining Loss: 0.01213559428013585\tValidation Loss: 0.012110556059299593\n",
      "Epoch 256  \tTraining Loss: 0.012084554549404493\tValidation Loss: 0.012059664716123795\n",
      "Epoch 257  \tTraining Loss: 0.012033997920262203\tValidation Loss: 0.012009246033663885\n",
      "Epoch 258  \tTraining Loss: 0.011983913946064365\tValidation Loss: 0.011959299669521821\n",
      "Epoch 259  \tTraining Loss: 0.011934301836296284\tValidation Loss: 0.011909811862345273\n",
      "Epoch 260  \tTraining Loss: 0.011885150303364513\tValidation Loss: 0.011860795561933705\n",
      "Epoch 261  \tTraining Loss: 0.011836467900777218\tValidation Loss: 0.011812230941689414\n",
      "Epoch 262  \tTraining Loss: 0.011788237767597095\tValidation Loss: 0.011764110614824052\n",
      "Epoch 263  \tTraining Loss: 0.011740453672091622\tValidation Loss: 0.011716427476205273\n",
      "Epoch 264  \tTraining Loss: 0.011693109470441734\tValidation Loss: 0.01166917420804104\n",
      "Epoch 265  \tTraining Loss: 0.01164619654603866\tValidation Loss: 0.011622347707829201\n",
      "Epoch 266  \tTraining Loss: 0.01159970889166163\tValidation Loss: 0.011575937955291157\n",
      "Epoch 267  \tTraining Loss: 0.011553639050168296\tValidation Loss: 0.011529939465199686\n",
      "Epoch 268  \tTraining Loss: 0.01150797892937931\tValidation Loss: 0.011484347602456025\n",
      "Epoch 269  \tTraining Loss: 0.01146272430251948\tValidation Loss: 0.011439159293034202\n",
      "Epoch 270  \tTraining Loss: 0.011417872290436762\tValidation Loss: 0.011394382759911016\n",
      "Epoch 271  \tTraining Loss: 0.011373429495855744\tValidation Loss: 0.01135000444608856\n",
      "Epoch 272  \tTraining Loss: 0.011329387689914256\tValidation Loss: 0.011306008140625538\n",
      "Epoch 273  \tTraining Loss: 0.011285730055841034\tValidation Loss: 0.011262394697709548\n",
      "Epoch 274  \tTraining Loss: 0.011242455310338397\tValidation Loss: 0.0112191717463135\n",
      "Epoch 275  \tTraining Loss: 0.011199570927209522\tValidation Loss: 0.011176327447750736\n",
      "Epoch 276  \tTraining Loss: 0.011157066458489271\tValidation Loss: 0.011133851643336677\n",
      "Epoch 277  \tTraining Loss: 0.011114933858955917\tValidation Loss: 0.011091739119468957\n",
      "Epoch 278  \tTraining Loss: 0.011073161616354136\tValidation Loss: 0.01104998023725401\n",
      "Epoch 279  \tTraining Loss: 0.011031742551369045\tValidation Loss: 0.011008576397347926\n",
      "Epoch 280  \tTraining Loss: 0.010990682908579083\tValidation Loss: 0.010967550121435295\n",
      "Epoch 281  \tTraining Loss: 0.010950005762661693\tValidation Loss: 0.010926865133629516\n",
      "Epoch 282  \tTraining Loss: 0.010909668940715437\tValidation Loss: 0.010886515108291549\n",
      "Epoch 283  \tTraining Loss: 0.010869667487564407\tValidation Loss: 0.01084650015466822\n",
      "Epoch 284  \tTraining Loss: 0.010830001064753268\tValidation Loss: 0.010806820100076657\n",
      "Epoch 285  \tTraining Loss: 0.010790667936374823\tValidation Loss: 0.010767464390409136\n",
      "Epoch 286  \tTraining Loss: 0.01075165770288327\tValidation Loss: 0.010728431447565374\n",
      "Epoch 287  \tTraining Loss: 0.010712969773559473\tValidation Loss: 0.010689720567608776\n",
      "Epoch 288  \tTraining Loss: 0.010674603580822485\tValidation Loss: 0.010651328315618136\n",
      "Epoch 289  \tTraining Loss: 0.010636556169380595\tValidation Loss: 0.010613280115232278\n",
      "Epoch 290  \tTraining Loss: 0.010598857382716362\tValidation Loss: 0.010575566954233041\n",
      "Epoch 291  \tTraining Loss: 0.010561487636686578\tValidation Loss: 0.010538155344575785\n",
      "Epoch 292  \tTraining Loss: 0.010524419189325125\tValidation Loss: 0.01050103932687172\n",
      "Epoch 293  \tTraining Loss: 0.010487647788736999\tValidation Loss: 0.010464217777263828\n",
      "Epoch 294  \tTraining Loss: 0.010451170781944269\tValidation Loss: 0.010427701953104563\n",
      "Epoch 295  \tTraining Loss: 0.010414996499129602\tValidation Loss: 0.010391470601924475\n",
      "Epoch 296  \tTraining Loss: 0.010379103384061974\tValidation Loss: 0.010355522013163017\n",
      "Epoch 297  \tTraining Loss: 0.010343492967605747\tValidation Loss: 0.010319851726459639\n",
      "Epoch 298  \tTraining Loss: 0.01030816065298337\tValidation Loss: 0.01028446074162276\n",
      "Epoch 299  \tTraining Loss: 0.010273106244291352\tValidation Loss: 0.010249357398094964\n",
      "Epoch 300  \tTraining Loss: 0.010238338749157656\tValidation Loss: 0.010214525988549099\n"
     ]
    }
   ],
   "source": [
    "from nn.nn import NeuralNetwork\n",
    "\n",
    "nn_arch = [\n",
    "    {'input_dim': 68, 'output_dim': 128, 'activation': 'relu'},\n",
    "    {'input_dim': 128, 'output_dim': 64, 'activation': 'relu'},\n",
    "    {'input_dim': 64, 'output_dim': 1, 'activation': 'sigmoid'}\n",
    "]\n",
    "\n",
    "\n",
    "classifier = NeuralNetwork(nn_arch=nn_arch, lr=5.0, seed=42, batch_size=100, epochs=300, loss_function='binary_cross_entropy')\n",
    "\n",
    "\n",
    "train_loss, val_loss = classifier.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(val_loss, label='val loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_val_prob = classifier.predict(X_val)\n",
    "y_pred_label = (y_val_prob > 0.5).astype(int).T\n",
    "\n",
    "y_pred_label = y_pred_label.squeeze()\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "\n",
    "print('Accuracy is:', round( accuracy ,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*Explain why you chose the sampling scheme you did:*\n",
    "I chose to upsample my data. Downsampling and upsampling each have pros and cons\n",
    "The pros of using upsampling, which is what I chose, is that we get to use all of the data we have on deck.\n",
    "The downside is that your upsampled labels will be over-represented... this is ok as long as your upsampled class\n",
    "is well representative of your groud truth distribution. \n",
    "\n",
    "\n",
    "\n",
    "*Explain your choice of loss function and hyperparameters:*\n",
    "I wanted to start with, which what I ended up going with, a simple NN. Input, two middle, and output.\n",
    "Maybe I could've started with a simpler one... buth this seems to work well.\n",
    "I played around with learning rate, and foudn 5 to be ok. I bet we can up it more, but 5 did the job.\n",
    "I honestly don't have much intution on batch_size. I wanted for things not to run too slow, so I used 100.\n",
    "I found loss stabilized at ~300, thus I stopped it there.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
